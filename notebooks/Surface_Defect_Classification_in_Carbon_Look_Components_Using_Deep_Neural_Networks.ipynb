{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Quality Control of Carbon Look Components via Surface Defect Classification with Deep Neural Networks\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/airtlab/surface-defect-classification-in-carbon-look-components-using-deep-neural-networks/blob/master/notebooks/Surface_Defect_Classification_in_Carbon_Look_Components_Using_Deep_Neural_Networks.ipynb)\n",
        "\n",
        "This notebook contains the source code of the experiments presented in\n",
        ">A. Silenzi, S. Tomassini, N. Falcionelli, P. Contardo, A. Bonci, A.F. Dragoni, P. Sernani, *Quality Control of Carbon Look Components via Surface Defect Classification with Deep Neural Networks*.\n",
        "\n",
        "The paper is currently under review for the publication in the [Sensors MDPI journal](https://www.mdpi.com/journal/sensors).\n",
        "\n",
        "Specifically, the experiments are **accuracy tests of ten different 2D Convolutional Neural Networks (2D CNNs) pretrained on Imagenet**. The models are combined with fully connected layers to classify images of carbon-look components into defective and non-defective and to recognize different types of surface defects. Such models perform a classification on samples of a real case study.\n",
        "\n",
        "The image database is publicly available in a dedicated GitHub repository:\n",
        "> <https://github.com/airtlab/surface-defect-classification-in-carbon-look-components-dataset>\n",
        "\n",
        "The tested 2D CNNs are:\n",
        "\n",
        "- VGG16 ([https://keras.io/api/applications/vgg/#vgg16-function](https://keras.io/api/applications/vgg/#vgg16-function))\n",
        "- VGG19 ([https://keras.io/api/applications/vgg/#vgg19-function](https://keras.io/api/applications/vgg/#vgg19-function))\n",
        "- ResNet50V2 ([https://keras.io/api/applications/resnet/#resnet50v2-function](https://keras.io/api/applications/resnet/#resnet50v2-function))\n",
        "- ResNet101V2 ([https://keras.io/api/applications/resnet/#resnet101v2-function](https://keras.io/api/applications/resnet/#resnet101v2-function))\n",
        "- ResNet152V2 ([https://keras.io/api/applications/resnet/#resnet152v2-function](https://keras.io/api/applications/resnet/#resnet152v2-function))\n",
        "- InceptionV3 ([https://keras.io/api/applications/inceptionv3](https://keras.io/api/applications/inceptionv3))\n",
        "- MobileNetV2 ([https://keras.io/api/applications/mobilenet/#mobilenetv2-function](https://keras.io/api/applications/mobilenet/#mobilenetv2-function))\n",
        "- NASNetMobile ([https://keras.io/api/applications/nasnet/#nasnetmobile-function](https://keras.io/api/applications/nasnet/#nasnetmobile-function))\n",
        "- DenseNet121 ([https://keras.io/api/applications/densenet/#densenet121-function](https://keras.io/api/applications/densenet/#densenet121-function))\n",
        "- Xception ([https://keras.io/api/applications/xception/](https://keras.io/api/applications/xception/))\n",
        "\n",
        "### Note\n",
        "\n",
        "The results presented in the paper are computed with a **GPU runtime**. **10 randomized tests for each model** were performed, to generalize the performance of the proposed model. Due to the randomization of the dataset splitting and non-deterministic behaviour of GPU computation, the results can slightly change across different runs.\n",
        "\n",
        "For more information about non-determism on GPU with TensorFlow check <https://github.com/NVIDIA/framework-determinism>."
      ],
      "metadata": {
        "id": "jcjd_smLfqHX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 Preliminary Operations\n",
        "The following cells:\n",
        "- install the packages used in the experiments (opencv, matplotlib, scikit-learn, scikit-image, pands). If the experiments run in Google Colab, these packages are already available and there is no need to install them manually;\n",
        "- print some information such as the version of the used packages (Keras, Tensorflow, Numpy, Scikit-learn), the CPU, and the GPU of the machine hosting the notebook;\n",
        "- import the libraries used for the experiments\n",
        "- **clone the image repository** into the /datarepo directory."
      ],
      "metadata": {
        "id": "R6ltAvj1w9gr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "6d394377-6a34-4a19-8e36-8388fe85a932",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "PPREVHULkfSw"
      },
      "outputs": [],
      "source": [
        "# Installs used package. There is no need to run this cell in Google Colab\n",
        "!pip install opencv-python-headless\n",
        "!pip install -U matplotlib\n",
        "!pip install -U scikit-learn\n",
        "!pip install pandas\n",
        "!pip install -U scikit-image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "9f55d057-dff2-423a-8c6b-424c10afd2c5",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "wyTBshK9Mbqy"
      },
      "outputs": [],
      "source": [
        "# Keras, Tensorflow, Scikit-Learn versions installed\n",
        "\n",
        "from keras import __version__\n",
        "from keras import backend as K\n",
        "import sklearn\n",
        "import matplotlib\n",
        "import cv2\n",
        "import numpy\n",
        "import scipy\n",
        "\n",
        "print('Using Scipy version: {}.'.format(scipy.__version__))\n",
        "print('Using Numpy version: {}.'.format(numpy.__version__))\n",
        "print('Using Scikit-learn version: {}.'.format(sklearn.__version__))\n",
        "print('Using OpenCV version: {}.'.format(cv2.__version__))\n",
        "print('Using Matplotlib version: {}.'.format(matplotlib.__version__))\n",
        "print('Using Keras version:', __version__, 'backend:', K.backend())\n",
        "\n",
        "if K.backend() == \"tensorflow\":\n",
        "    import tensorflow as tf\n",
        "    device_name = tf.test.gpu_device_name()\n",
        "    if device_name == '':\n",
        "        device_name = \"None\"\n",
        "    print('Using TensorFlow version:', tf.__version__, ', GPU:', device_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "fc66ab5d-0fab-457d-b174-0d17568154a2",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "WiHYFoMIMzRR"
      },
      "outputs": [],
      "source": [
        "# CPU in use\n",
        "!cat /proc/cpuinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "cae54226-7878-4f44-925c-6ef217fd9aa6",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "10BLjFY3jvO7"
      },
      "outputs": [],
      "source": [
        "# GPU in use\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "29c0b2ef-0461-4d18-896f-1bf7a8c77eba",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "EkzQyTGPK17p"
      },
      "outputs": [],
      "source": [
        "# Import of used libraries\n",
        "\n",
        "from keras.models import model_from_json, Model\n",
        "import os, sys, re, codecs, csv\n",
        "from PIL import Image\n",
        "from os import listdir, stat\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import random\n",
        "from random import shuffle\n",
        "import shutil\n",
        "import argparse\n",
        "\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
        "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, RocCurveDisplay\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Embedding, Activation, Flatten, TimeDistributed, Bidirectional, LSTM, BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPool2D\n",
        "from tensorflow.keras.applications.xception import Xception, preprocess_input as xception_preprocess_input\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input as vgg16_preprocess_input\n",
        "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input as vgg19_preprocess_input\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet50V2, preprocess_input as resnet_v2_preprocess_input\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet101V2\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet152V2\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input as inception_v3_preprocess_input\n",
        "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input as inception_resnet_v2_preprocess_input\n",
        "from tensorflow.keras.applications.densenet import DenseNet121, preprocess_input as densenet_preprocess_input\n",
        "from tensorflow.keras.applications.nasnet import NASNetMobile, preprocess_input as nasnet_preprocess_input\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input as mobilenet_v2_preprocess_input\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "from io import BytesIO\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import preprocessing\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras import models\n",
        "from keras.regularizers import l2\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import initializers, regularizers, constraints, layers\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "import skimage\n",
        "import scipy\n",
        "from scipy import ndimage, misc\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "7ef0154d-f483-421c-a247-1f98e75efe26",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "XP9JG_qekfTG"
      },
      "outputs": [],
      "source": [
        "# Downloads the image dataset for the classification of carbon look components\n",
        "!mkdir datarepo\n",
        "!git clone https://github.com/airtlab/surface-defect-classification-in-carbon-look-components-dataset.git datarepo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "62df5de0-3f6a-4531-b3d1-496eda923da8",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "-hswYkRcqpKO"
      },
      "source": [
        "## 2 Image Preprocessing\n",
        "\n",
        "The following cells:\n",
        "- define **utility functions for data preprocessing**. Specifically, these functions\n",
        "    - reduce the image size;\n",
        "    - perform data augmentation by flipping images horizontally and vertically\n",
        "    - copy the images to different paths;\n",
        "    - convert to gray scale;\n",
        "    - perform illumination normalization;\n",
        "- **run the image preprocessing**. Note that **only data augmentation** is performed (the best results were achieved without converting to grayscale and without illumination normalization). In the augmented image datasets, the original images are included as well. After these operations, four datasets are available for the experiments\n",
        "    - **the original dataset for binary classification**, which contains images from two classes, i.e. negative (no defects) and positive (with defects). There are **200 images per class**, with a total of 400 images;\n",
        "    - **the augmented dataset for binary classification**, which contains the images of the previous dataset flipped horizontally, vertically, and in their original shape as well. There are **600 images per class**, with a total of 1200 images;\n",
        "    - **the original dataset for multi-class classification**, which contains images from three classes, i.e. negative (no defects), with recoverable defects, and with non-recoverable defects. There are **500 images per class**, with a total of 1500 images;\n",
        "    - **the augmented dataset for multi-class classification**, which contains the images of the previous fataset flipped horizontally, vertically, and in their original shape as well. There are **1500 images per class**, with a total of 4500 images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "a5768547-457e-483d-9a08-f0b52a15db6f",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "XKj8-KWERBBE"
      },
      "outputs": [],
      "source": [
        "# Constants with the paths to the datasets\n",
        "ORIGINAL_BINARY_DATASET_DIR = 'datarepo/carbon-binary'\n",
        "AUGMENTED_BINARY_DATASET_DIR = 'datarepo/carbon-binary-augmented'\n",
        "ORIGINAL_MULTI_DATASET_DIR = 'datarepo/carbon-multiclass'\n",
        "AUGMENTED_MULTI_DATASET_DIR = 'datarepo/carbon-multiclass-augmented'\n",
        "\n",
        "def downsize(path):\n",
        "\n",
        "    \"\"\" Downsize images byte dimesion\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    path : str\n",
        "           Path to the folder with images to be downsized\n",
        "    \"\"\"\n",
        "    for defect_type in os.listdir(path):\n",
        "        read_path = path + '/' + defect_type + '/'\n",
        "        for files in os.listdir(read_path):\n",
        "            img_to_downsize = Image.open(read_path + files)\n",
        "            img_to_downsize.save(read_path + files, optimize=True, quality=85)\n",
        "\n",
        "\n",
        "def data_augmentation(dataset_path, augmented_dataset_path):\n",
        "\n",
        "    \"\"\" Data augmentation function for horizontal and vertical flip\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataset_path : str\n",
        "                   Path to the folder with images to be augmented\n",
        "    augmented_dataset_path : str\n",
        "                             Destination path for the synthetic samples. It will\n",
        "                             contain the same folders which are in dataset_path,\n",
        "                             with new data\n",
        "    \"\"\"\n",
        "\n",
        "    path = dataset_path\n",
        "\n",
        "    if not os.path.exists(augmented_dataset_path):\n",
        "        os.makedirs(augmented_dataset_path)\n",
        "\n",
        "    for defect_type in os.listdir(path):\n",
        "        if path == 'datarepo/carbon-binary':\n",
        "            i = 200\n",
        "        elif path == 'datarepo/carbon-multiclass':\n",
        "            i = 500\n",
        "        if not os.path.exists(augmented_dataset_path + '/' + defect_type):\n",
        "            os.makedirs(augmented_dataset_path + '/' + defect_type)\n",
        "            read_path = path + '/' + defect_type + '/'\n",
        "            write_path = augmented_dataset_path + '/' + defect_type + '/'\n",
        "        for files in os.listdir(read_path):\n",
        "            img_to_augment = cv2.imread(read_path + files)\n",
        "            horizontal_img = cv2.flip(img_to_augment, 0)\n",
        "            vertical_img = cv2.flip(img_to_augment, 1)\n",
        "            root, ext = os.path.splitext(files)\n",
        "            if defect_type == 'negative':\n",
        "                cv2.imwrite(os.path.join(write_path, 'negative_' + str(i + 1) + ext), horizontal_img)\n",
        "                cv2.imwrite(os.path.join(write_path, 'negative_' + str(i + 2) + ext), vertical_img)\n",
        "            elif defect_type == 'positive':\n",
        "                cv2.imwrite(os.path.join(write_path, 'positive_' + str(i + 1) + ext), horizontal_img)\n",
        "                cv2.imwrite(os.path.join(write_path, 'positive_' + str(i + 2) + ext), vertical_img)\n",
        "            elif defect_type == 'non_recoverable_defects':\n",
        "                cv2.imwrite(os.path.join(write_path, 'nrd_' + str(i + 1) + ext), horizontal_img)\n",
        "                cv2.imwrite(os.path.join(write_path, 'nrd_' + str(i + 2) + ext), vertical_img)\n",
        "            elif defect_type == 'recoverable_defects':\n",
        "                cv2.imwrite(os.path.join(write_path, 'rd_' + str(i + 1) + ext), horizontal_img)\n",
        "                cv2.imwrite(os.path.join(write_path, 'rd_' + str(i + 2) + ext), vertical_img)\n",
        "            i += 2\n",
        "\n",
        "\n",
        "def copy_original_files(dataset_path, augmented_dataset_path):\n",
        "\n",
        "    \"\"\" Copies the original files into the augmented dataset\n",
        "\n",
        "    It copies all the files included in the folders at dataset_path, in the same folders\n",
        "    in augmented_dataset_path\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataset_path : str\n",
        "                   Path to the folder with images to be augmented\n",
        "    augmented_dataset_path : str\n",
        "                             Destination path for the copied files\n",
        "    \"\"\"\n",
        "\n",
        "    for defect_type in os.listdir(dataset_path):\n",
        "        for files in os.listdir(dataset_path + '/' + defect_type):\n",
        "            shutil.copyfile((dataset_path + '/' + defect_type + '/' + files), (augmented_dataset_path + '/' + defect_type + '/' + files))\n",
        "\n",
        "\n",
        "def convert_gray(path):\n",
        "\n",
        "    \"\"\" Convert path images to grayscale\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataset_path : str\n",
        "                   Path to the folder with images to be converted\n",
        "    \"\"\"\n",
        "    for defect_type in os.listdir(path):\n",
        "        read_path = path + '/' + defect_type + '/'\n",
        "        for files in os.listdir(read_path):\n",
        "            img = cv2.imread(read_path + files)\n",
        "            gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "            cv2.imwrite(os.path.join(read_path + files), gray)\n",
        "\n",
        "\n",
        "def illumination_normalization(path):\n",
        "\n",
        "    \"\"\" Function for Local Illumination Normalization (CLAHE)\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    path : str\n",
        "           Path to the folder with images to be augmented\n",
        "    \"\"\"\n",
        "    for defect_type in os.listdir(path):\n",
        "        read_path = path + '/' + defect_type + '/'\n",
        "        for files in os.listdir(read_path):\n",
        "            img = cv2.imread(read_path + files, 0)\n",
        "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8)) # Create a CLAHE object (Arguments are optional)\n",
        "            new_img = clahe.apply(img)\n",
        "            cv2.imwrite(os.path.join(read_path + files), new_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "676a62bd-6a07-440b-8bae-734dadf69452",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "C-6ajG7BSKbq"
      },
      "outputs": [],
      "source": [
        "# Creates the augmented dataset and copies there also the original data\n",
        "\n",
        "#downsize(original_data_dir)\n",
        "\n",
        "data_augmentation(ORIGINAL_BINARY_DATASET_DIR, AUGMENTED_BINARY_DATASET_DIR)\n",
        "copy_original_files(ORIGINAL_BINARY_DATASET_DIR, AUGMENTED_BINARY_DATASET_DIR)\n",
        "data_augmentation(ORIGINAL_MULTI_DATASET_DIR, AUGMENTED_MULTI_DATASET_DIR)\n",
        "copy_original_files(ORIGINAL_MULTI_DATASET_DIR, AUGMENTED_MULTI_DATASET_DIR)\n",
        "\n",
        "#convert_gray(original_data_dir)\n",
        "#recoverable_defects = os.listdir(original_data_dir + '/recoverable_defects/')\n",
        "#sample_image = load_img(os.path.join(original_data_dir + '/recoverable_defects/', recoverable_defects[111]), target_size=(224,224))\n",
        "#plt.imshow(sample_image)\n",
        "#plt.show()\n",
        "\n",
        "#sample_image = cv2.imread(os.path.join(original_data_dir + '/recoverable_defects/', recoverable_defects[111]))\n",
        "#horizontal_img = cv2.flip(sample_image, 0)\n",
        "#plt.imshow(horizontal_img)\n",
        "#plt.show()\n",
        "# Convert original and augmented dataset to grayscale\n",
        "#convert_gray(original_data_dir)\n",
        "#convert_gray(augmented_data_dir)\n",
        "\n",
        "# Apply normalization for both datasets\n",
        "#illumination_normalization(original_data_dir)\n",
        "#illumination_normalization(augmented_data_dir)\n",
        "\n",
        "#sample_image = cv2.imread(os.path.join(original_data_dir + '/recoverable_defects/', recoverable_defects[111]))\n",
        "#plt.imshow(sample_image)\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "856391f7-4cce-4c94-b06c-9a5c52461961",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "ipOZ8O3q5IIE"
      },
      "source": [
        "## 3 Binary classification experiments\n",
        "\n",
        "The following cells:\n",
        "\n",
        "- define utility functions **to download a pretrained model** and build and end-to-end network for binary classification based on a pretrained model;\n",
        "- define **ten utility functions to build the ten end-to-end deep neural networks** developed for the experiments to test the binary classification of carbon look component images into negative (no defects) and positive (with defects).\n",
        "- define the **utility function to run an experiment with the binary classification**. An experiment consists of tests repeated 10 times with the **stratified shuffle split cross-validation scheme**. In each split 80% of data are used for training, and 20% of data are used for testing. 12,5% of the training data (i.e. 10% of the entire dataset) is used for validation. In other words, in each test **70% of data are actually for training, 10% for validation, and 20% for testing.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "ad124f57-3b7f-4a41-8589-82f816fe727b",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "z60YI-KukfTN"
      },
      "outputs": [],
      "source": [
        "def GetPretrainedModel(ModelConstructor, input_shape=(224,224,3), print_summary=True, layers_to_finetune=0):\n",
        "\n",
        "    \"\"\" Builds a pretrained 2D CNN with the Imagenet weights, freezing all layers except \"layers_to_finetune\"\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    ModelConstructor : Callable[[bool], [str], [tuple], Sequential]\n",
        "                       Function that download the pretrained model, i.e. one of the Keras applications:\n",
        "                       https://keras.io/api/applications/\n",
        "                       The arguments are include_top, weights, and input_shape.\n",
        "    input_shape : tuple\n",
        "                  The input shape for the pretrained model.\n",
        "    print_summary : bool\n",
        "                    If True prints the model summary.\n",
        "    layers_to_finetune : bool\n",
        "                 The number of final layers that should not be freezed. Freezes all the layers if\n",
        "                 lower or equal than 0, or greater of the number of layers of the network.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    model : Sequential\n",
        "          The instantiated model.\n",
        "    \"\"\"\n",
        "\n",
        "    model = ModelConstructor(include_top=False, weights=\"imagenet\", input_shape=input_shape)\n",
        "\n",
        "    if print_summary:\n",
        "        print('Pretrained model')\n",
        "        model.summary()\n",
        "    if layers_to_finetune > 0 and layers_to_finetune <= len( model.layers):\n",
        "        for layer in model.layers[:-layers_to_finetune]:\n",
        "            layer.trainable = False\n",
        "    else:\n",
        "        for layer in model.layers:\n",
        "            layer.trainable = False\n",
        "    return model\n",
        "\n",
        "\n",
        "def GetEndToEndModel(GetPretrainedModel, ModelConstructor, optimizer, loss, input_shape=(224,224,3),\n",
        "    print_summary=True, layers_to_finetune=0, include_global_avarage=True, include_batch_norm=True,\n",
        "    dense_units=[512], classes=2):\n",
        "\n",
        "    \"\"\" Creates the end to end model composed of a pretrained deep neural network (one of the keras\n",
        "    applications with the Imagenet weights) and fully connected dense layers trained from scratch).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    GetPretrainedModel : Callable[[Callable[[bool], [str], [tuple], Sequential]], [tuple], [bool], [int], Sequential]\n",
        "                Function that instantiates the pretrained model.\n",
        "    ModelConstructor : Callable[[bool], [str], [tuple], Sequential]\n",
        "                       Function that download the pretrained model, i.e. one of the Keras applications:\n",
        "                       https://keras.io/api/applications/\n",
        "                       The arguments are include_top, weights, and input_shape.\n",
        "    optimizer : Optimizer\n",
        "                One of the Keras optmizers https://keras.io/api/optimizers/\n",
        "    loss : str\n",
        "           String that identifies the loss function to be applied\n",
        "    input_shape : tuple\n",
        "                  The input shape for the pretrained model.\n",
        "    print_summary : bool\n",
        "                    If True prints the model summary.\n",
        "    layers_to_finetune : bool\n",
        "                 The number of final layers that should not be freezed. Freezes all the layers if\n",
        "                 lower or equal than 0, or greater of the number of layers of the network.\n",
        "    include_global_avarage : bool\n",
        "                             If True, includes a GlobalAvaragePooling2D layer after the pretrained model.\n",
        "    include_batch_norm : bool\n",
        "                         If True, includes a BatchNormalization layer after the pretrained model.\n",
        "    dense_unit : list\n",
        "                 List of ints where each int represent the number of units of dense layers to be added to the model.\n",
        "    classes : int\n",
        "              Number of classes in output for the model, i.e. the number of neurons of the final Softmax layer.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    model : Sequential\n",
        "            The instantiated model\n",
        "    \"\"\"\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    # Add the convolutional base model\n",
        "    model.add(GetPretrainedModel(ModelConstructor,input_shape,print_summary,layers_to_finetune))\n",
        "\n",
        "    if include_global_avarage:\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "    #model.add(GlobalMaxPool2D())\n",
        "    #model.add(MaxPooling2D())\n",
        "\n",
        "    if include_batch_norm:\n",
        "        model.add(BatchNormalization())\n",
        "    #model.add(Dropout(0.5))\n",
        "\n",
        "    # Add new layers (by default, kernel_initializer = 'glorot_uniform')\n",
        "    model.add(Flatten())\n",
        "    #model.add(Dense(1024, activation='relu'))\n",
        "    #model.add(Dense(1024, activation='relu'))\n",
        "    #model.add(Dense(1024, activation='relu'))\n",
        "    #model.add(Dense(512, activation='relu'))\n",
        "    for dense_unit in dense_units:\n",
        "        model.add(Dense(dense_unit, activation='relu'))\n",
        "\n",
        "    model.add(Dense(classes, activation='softmax'))\n",
        "\n",
        "    if print_summary:\n",
        "        print('End to end model')\n",
        "        model.summary()\n",
        "\n",
        "    model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "326d5dd9-a09d-40e5-928f-38fe71b94da6",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "-TIxLxFYkfTO"
      },
      "outputs": [],
      "source": [
        "def GetBestBinaryVGG16Model(print_summary=True) :\n",
        "    return GetEndToEndModel(GetPretrainedModel, VGG16, optimizers.SGD(learning_rate=0.0001, momentum=0.9),\n",
        "    'binary_crossentropy', (224,224,3), print_summary, 8, True, False, [512], 2)\n",
        "\n",
        "def GetBestBinaryVGG19Model(print_summary=True) :\n",
        "    return GetEndToEndModel(GetPretrainedModel, VGG19, optimizers.SGD(learning_rate=0.001, momentum=0.9),\n",
        "    'binary_crossentropy', (224,224,3), print_summary, 8, True, False, [512], 2)\n",
        "\n",
        "def GetBestBinaryResNet50V2Model(print_summary=True) :\n",
        "    return GetEndToEndModel(GetPretrainedModel, ResNet50V2, optimizers.Adam(learning_rate=0.0001),\n",
        "    'binary_crossentropy', (224,224,3), print_summary, 8, True, False, [512], 2)\n",
        "\n",
        "def GetBestBinaryResNet101V2Model(print_summary=True) :\n",
        "    return GetEndToEndModel(GetPretrainedModel, ResNet101V2, optimizers.Adam(learning_rate=0.001),\n",
        "    'binary_crossentropy', (224,224,3), print_summary, 8, True, False, [512], 2)\n",
        "\n",
        "def GetBestBinaryResNet152V2Model(print_summary=True) :\n",
        "    return GetEndToEndModel(GetPretrainedModel, ResNet152V2, optimizers.Adam(learning_rate=0.0001),\n",
        "    'binary_crossentropy', (224,224,3), print_summary, 8, True, False, [512], 2)\n",
        "\n",
        "def GetBestBinaryInceptionV3Model(print_summary=True) :\n",
        "    return GetEndToEndModel(GetPretrainedModel, InceptionV3, optimizers.SGD(learning_rate=0.001, momentum=0.9),\n",
        "    'binary_crossentropy', (299,299,3), print_summary, 8, True, False, [512], 2)\n",
        "\n",
        "def GetBestBinaryMobileNetV2Model(print_summary=True) :\n",
        "    return GetEndToEndModel(GetPretrainedModel, MobileNetV2, optimizers.Adam(learning_rate=0.0001),\n",
        "    'binary_crossentropy', (224,224,3), print_summary, 8, True, False, [256, 128], 2)\n",
        "\n",
        "def GetBestBinaryNasNetMobileModel(print_summary=True) :\n",
        "    return GetEndToEndModel(GetPretrainedModel, NASNetMobile, optimizers.Adam(learning_rate=0.0001),\n",
        "    'binary_crossentropy', (224,224,3), print_summary, 4, True, False, [256, 128], 2)\n",
        "\n",
        "def GetBestBinaryDenseNet121Model(print_summary=True) :\n",
        "    return GetEndToEndModel(GetPretrainedModel, DenseNet121, optimizers.Adam(learning_rate=0.0001),\n",
        "    'binary_crossentropy', (224,224,3), print_summary, 8, True, False, [512], 2)\n",
        "\n",
        "def GetBestBinaryXceptionModel(print_summary=True) :\n",
        "    return GetEndToEndModel(GetPretrainedModel, Xception, optimizers.Adam(learning_rate=0.0001),\n",
        "    'binary_crossentropy', (299,299,3), print_summary, 4, True, False, [256, 128], 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "5612e840-3b93-4d69-9962-33365ef5d824",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "qnJWt6fp5L-k"
      },
      "outputs": [],
      "source": [
        "def runExperiment(GetConvModel, Preprocess_input, input_shape, batchSize, path,\n",
        "    Model_name, folderName, rState, split_number=10):\n",
        "\n",
        "    \"\"\"\" Runs a classifier test on the binary dataset, using the stratified shuffled splits, with\n",
        "        70% of data for training, 10% for validation, 20% for test\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    GetConvModel : Callable[Sequential]\n",
        "                   Function returning the sequential model to be tested.\n",
        "    Preprocess_input : Callable[[][]]\n",
        "    input_shape : tuple\n",
        "                  Shape of a model's input.\n",
        "    batchSize : int\n",
        "                Batch size to be used for training and testing\n",
        "    path : str\n",
        "           Path to the folder with images to be processed\n",
        "    Model_name : str\n",
        "                 Model name to be used in the title of AUC-ROC plot\n",
        "    folderName : str\n",
        "                 Name for the folder to store the AUC-ROC plot.\n",
        "    rState : int, RandomState instance or None\n",
        "             Controls the randomness of the training and testing indices produced.\n",
        "             Pass an int for reproducible output across multiple function calls.\n",
        "    split_number : int\n",
        "                   Number of split to run the Stratified Shuffle Split (default 5)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Prepare samples tensor and label array\n",
        "    negative = os.listdir(path + '/negative/')\n",
        "    count_negative = len(negative)\n",
        "    print(\"Negative images: \", count_negative)\n",
        "    positive = os.listdir(path + '/positive/')\n",
        "    count_positive = len(positive)\n",
        "    print(\"Positive images: \", count_positive)\n",
        "    total_samples = count_negative + count_positive\n",
        "    print(\"Total images: \", total_samples)\n",
        "    imgs_array = np.ones((total_samples, input_shape[0], input_shape[1], input_shape[2]))\n",
        "    print(\"Tensor shape \", imgs_array.shape, \"\\n\")\n",
        "    label_array = []\n",
        "\n",
        "    index = 0\n",
        "\n",
        "    for defect_type in os.listdir(path):\n",
        "        read_path = path + '/' + defect_type + '/'\n",
        "        for filename in os.listdir(read_path):\n",
        "            imgs = load_img(os.path.join(read_path, filename), target_size=(input_shape[0], input_shape[1]))\n",
        "            imgs = img_to_array(imgs)\n",
        "            imgs = imgs.reshape((1, imgs.shape[0], imgs.shape[1], imgs.shape[2]))\n",
        "            imgs = Preprocess_input(imgs)\n",
        "            imgs_array[index,:,:,:] = imgs\n",
        "            if defect_type == 'negative':\n",
        "                label_array.append(0)\n",
        "            elif defect_type == 'positive':\n",
        "                label_array.append(1)\n",
        "            index += 1\n",
        "\n",
        "    X = imgs_array\n",
        "    y = label_array\n",
        "\n",
        "    # Makes y_samples a categorical matrix\n",
        "    y = to_categorical(y, num_classes = 2)\n",
        "    n_classes = y.shape[1]\n",
        "    nsplits = split_number\n",
        "    cv = StratifiedShuffleSplit(n_splits=nsplits, train_size=0.8, random_state = rState)\n",
        "\n",
        "    tprs = []\n",
        "    aucs = []\n",
        "    scores = []\n",
        "    prec_negative = np.zeros(shape=(nsplits))\n",
        "    prec_positive = np.zeros(shape=(nsplits))\n",
        "    recall_negative = np.zeros(shape=(nsplits))\n",
        "    recall_positive = np.zeros(shape=(nsplits))\n",
        "    f1Scores_negative = np.zeros(shape=(nsplits))\n",
        "    f1Scores_positive = np.zeros(shape=(nsplits))\n",
        "    mean_fpr = np.linspace(0, 1, 100)\n",
        "    plt.figure(num=1, figsize=(10,10))\n",
        "    i = 1\n",
        "\n",
        "    for train, test in cv.split(X, y):\n",
        "        X_train, X_val, y_train, y_val = train_test_split(X[train][:], y[train], test_size = 0.125, random_state = rState)\n",
        "        X_test, y_test = X[test], y[test]\n",
        "        model = GetConvModel(i==1)\n",
        "        es = EarlyStopping(monitor='val_loss', mode='min', patience=5, verbose=1, restore_best_weights=True)\n",
        "        history = model.fit(x=X_train, y=y_train, validation_data=(X_val, y_val), epochs=100, batch_size=batchSize, verbose=1, callbacks=[es], shuffle=True)\n",
        "\n",
        "        del X_train\n",
        "        del X_val\n",
        "\n",
        "        print(\"Computing scores...\")\n",
        "        evaluation = model.evaluate(X_test, y_test)\n",
        "        scores.append(evaluation)\n",
        "        print(\"Computing probs...\")\n",
        "        probas = model.predict(X_test, batch_size=batchSize, verbose=1)\n",
        "        y_true = y_test.argmax(axis=1)\n",
        "        pred = probas.argmax(axis=1)\n",
        "\n",
        "        #del X_test\n",
        "\n",
        "        # Compute ROC curve and area under the curve\n",
        "        fpr = dict()\n",
        "        tpr = dict()\n",
        "        roc_auc = dict()\n",
        "\n",
        "        for k in range(n_classes):\n",
        "            fpr[k], tpr[k], _ = roc_curve(y_test[:, k], probas[:, k])\n",
        "            roc_auc[k] = auc(fpr[k], tpr[k])\n",
        "\n",
        "        # Compute micro-average ROC curve and ROC area\n",
        "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), probas.ravel())\n",
        "        tprs.append(np.interp(mean_fpr, fpr[\"micro\"], tpr[\"micro\"]))\n",
        "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "        aucs.append(roc_auc[\"micro\"])\n",
        "        plt.plot(fpr[\"micro\"], tpr[\"micro\"], lw=2, alpha=0.3, label='ROC split %d (AUC = %0.4f)' % (i, roc_auc[\"micro\"]))\n",
        "\n",
        "        y_pred = np.round(pred)\n",
        "        report = classification_report(y_true, y_pred, target_names=['negative', 'positive'], output_dict=True)\n",
        "        prec_negative[i - 1] = report['negative']['precision']\n",
        "        prec_positive[i - 1] = report['positive']['precision']\n",
        "        recall_negative[i - 1] = report['negative']['recall']\n",
        "        recall_positive[i - 1] = report['positive']['recall']\n",
        "        f1Scores_negative[i - 1] = report['negative']['f1-score']\n",
        "        f1Scores_positive[i - 1] = report['positive']['f1-score']\n",
        "\n",
        "        print('confusion matrix split ' + str(i))\n",
        "        print(confusion_matrix(y_true, y_pred))\n",
        "        print(classification_report(y_true, y_pred, target_names=['negative', 'positive']))\n",
        "        print('Loss: ' + str(evaluation[0]))\n",
        "        print('Accuracy: ' + str(evaluation[1]))\n",
        "        print('\\n')\n",
        "\n",
        "        i += 1\n",
        "\n",
        "        del report\n",
        "        del model\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Chance', alpha=.8)\n",
        "\n",
        "    mean_tpr = np.mean(tprs, axis=0)\n",
        "    mean_auc = auc(mean_fpr, mean_tpr)\n",
        "    std_auc = np.std(aucs)\n",
        "    plt.plot(mean_fpr, mean_tpr, color='b', label=r'Mean ROC (AUC = %0.4f $\\pm$ %0.4f)' % (mean_auc, std_auc), lw=2, alpha=.8)\n",
        "\n",
        "    std_tpr = np.std(tprs, axis=0)\n",
        "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
        "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
        "    plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2, label=r'$\\pm$ 1 std. dev.')\n",
        "\n",
        "    plt.xlim([-0.01, 1.01])\n",
        "    plt.ylim([-0.01, 1.01])\n",
        "    plt.xlabel('False Positive Rate',fontsize=18)\n",
        "    plt.ylabel('True Positive Rate',fontsize=18)\n",
        "    plt.title('Cross-Validation ROC of ' + Model_name + ' model', fontsize=18)\n",
        "    plt.legend(loc=\"lower right\", prop={'size': 15})\n",
        "\n",
        "    np_scores = np.array(scores)\n",
        "    losses = np_scores[:, 0:1]\n",
        "    accuracies = np_scores[:, 1:2]\n",
        "    print('Losses')\n",
        "    print(losses)\n",
        "    print('Accuracies')\n",
        "    print(accuracies)\n",
        "    print('Precision class negative:\\n', prec_negative)\n",
        "    print('Precision class positive:\\n', prec_positive)\n",
        "    print('Recall class negative:\\n', recall_negative)\n",
        "    print('Recall class positive:\\n', recall_positive)\n",
        "    print('F1-scores class negative:\\n', f1Scores_negative)\n",
        "    print('F1-scores class positive:\\n', f1Scores_positive)\n",
        "    print(\"Avg loss: {0} +/- {1}\".format(np.mean(losses), np.std(losses)))\n",
        "    print(\"Avg accuracy: {0} +/- {1}\".format(np.mean(accuracies), np.std(accuracies)))\n",
        "    print(\"\\nAvg Precision class negative: {0} +/- {1}\".format(np.mean(prec_negative), np.std(prec_negative)))\n",
        "    print(\"Avg Precision class positive: {0} +/- {1}\".format(np.mean(prec_positive), np.std(prec_positive)))\n",
        "    print(\"\\nAvg Recall class negative: {0} +/- {1}\".format(np.mean(recall_negative), np.std(recall_negative)))\n",
        "    print(\"Avg Recall class positive: {0} +/- {1}\".format(np.mean(recall_positive), np.std(recall_positive)))\n",
        "    print(\"\\nAvg f1-score class negative: {0} +/- {1}\".format(np.mean(f1Scores_negative), np.std(f1Scores_negative)))\n",
        "    print(\"Avg f1-score class positive: {0} +/- {1}\".format(np.mean(f1Scores_positive), np.std(f1Scores_positive)))\n",
        "\n",
        "    plt.savefig(folderName + '/' + Model_name.replace('+', '') + '.pdf')\n",
        "    plt.show()\n",
        "\n",
        "    del imgs_array\n",
        "    del label_array\n",
        "    del X\n",
        "    del y\n",
        "    del prec_negative\n",
        "    del prec_positive\n",
        "    del recall_negative\n",
        "    del recall_positive\n",
        "    del f1Scores_negative\n",
        "    del f1Scores_positive\n",
        "    del accuracies\n",
        "    del losses\n",
        "    del np_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Experiments with the original binary dataset\n",
        "\n",
        "The following cells run the **tests on the original binary dataset**, model by model, for each of the ten compared neural networks. Before running the experiments a folder to store the AUC-ROC plots of the experiments is created. After each experiments, the imagenet weights of the tested neural network can be deleted, in case limited disk space is available."
      ],
      "metadata": {
        "id": "v0nnzIVW_WID"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "2d7891db-63a3-4030-b320-471f130a0f6b",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "d_8MuXBaqELc"
      },
      "outputs": [],
      "source": [
        "# Creates a folder to store the results of experiments with the binary dataset\n",
        "!mkdir binary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "1757013f-8505-424b-b6bf-74bcd7ae44ac",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "yK2HWdI_kfTR"
      },
      "outputs": [],
      "source": [
        "# Binary classification on the original dataset with VGG16\n",
        "runExperiment(GetBestBinaryVGG16Model, vgg16_preprocess_input, (224,224,3), 32, ORIGINAL_BINARY_DATASET_DIR, 'VGG16 + dense layers',\n",
        "    'binary', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "e88ecc43-3d74-42ae-a708-6ba7c9de1398",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "Gbhe4GfYkfTQ"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "e44346ce-706a-41f7-a3de-df3e90557a7c",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "6vluVQduqELe"
      },
      "outputs": [],
      "source": [
        "# Binary classification on the original dataset with VGG19\n",
        "runExperiment(GetBestBinaryVGG19Model, vgg19_preprocess_input, (224,224,3), 32, ORIGINAL_BINARY_DATASET_DIR,\n",
        "    'VGG19 + dense layers', 'binary', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "0a9fcb41-b10b-4cd4-bf81-d52b0bb8106a",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "stbqC9kIqELf"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "3115668a-348f-4be3-abd5-a09f34fcaec6",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "AZPmgUCcqELf"
      },
      "outputs": [],
      "source": [
        "# Binary classification on the original dataset with ResNet50V2\n",
        "runExperiment(GetBestBinaryResNet50V2Model, resnet_v2_preprocess_input, (224,224,3), 32, ORIGINAL_BINARY_DATASET_DIR,\n",
        "    'ResNet50V2 + dense layers', 'binary', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "3715d7c7-61d9-44b4-a841-18df5ac4e549",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "GTC3Go4NqELg"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "641d984f-9a56-4355-9004-7db9dc754ef1",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "5ivRYkN1qELg"
      },
      "outputs": [],
      "source": [
        "# Binary classification on the original dataset with ResNet101V2\n",
        "runExperiment(GetBestBinaryResNet101V2Model, resnet_v2_preprocess_input, (224,224,3), 32, ORIGINAL_BINARY_DATASET_DIR,\n",
        "    'ResNet101V2 + dense layers', 'binary', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "422c69ee-adcf-4bf7-ba6d-de6f11c4ca3a",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "vOgm_WFvqELh"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "0ae3536b-3d63-4e36-9e69-f0c5430f5a5f",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "d0fQRMXIqELh"
      },
      "outputs": [],
      "source": [
        "# Binary classification on the original dataset with ResNet152V2\n",
        "runExperiment(GetBestBinaryResNet152V2Model, resnet_v2_preprocess_input, (224,224,3), 32, ORIGINAL_BINARY_DATASET_DIR,\n",
        "    'ResNet152V2 + dense layers', 'binary', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "29a86153-cd1e-4b9b-8c39-1dbcc5455be3",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "1VyKRZd5qELh"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "48f81d75-aa25-4801-86f4-c24f5d49b6bc",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "gCURVrxPqELh"
      },
      "outputs": [],
      "source": [
        "# Binary classification on the original dataset with InceptionV3\n",
        "runExperiment(GetBestBinaryInceptionV3Model, inception_v3_preprocess_input, (299,299,3), 32, ORIGINAL_BINARY_DATASET_DIR,\n",
        "    'InceptionV3 + dense layers', 'binary', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "aa4722de-4557-4338-9190-e575f71e5d16",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "aLQTmE1kqELs"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "d817e137-a1d4-4576-8196-35bbd28740d9",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "KYJokmcNqELs"
      },
      "outputs": [],
      "source": [
        "# Binary classification on the original dataset with MobileNetV2\n",
        "runExperiment(GetBestBinaryMobileNetV2Model, mobilenet_v2_preprocess_input, (224,224,3), 32, ORIGINAL_BINARY_DATASET_DIR,\n",
        "    'MobileNetV2 + dense layers', 'binary', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "22a2a3d8-be51-4c42-8a2b-c236afe0844a",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "XPWjWalxqEL1"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "e457b521-8e74-47b4-bea3-4ee6078ceeb1",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "m30YJG2KqEL1"
      },
      "outputs": [],
      "source": [
        "# Binary classification on the original dataset with NASNetMobile\n",
        "runExperiment(GetBestBinaryNasNetMobileModel, nasnet_preprocess_input, (224,224,3), 32, ORIGINAL_BINARY_DATASET_DIR,\n",
        "    'NASNetMobile + dense layers', 'binary', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "86f4188d-56f3-4439-b4af-c06354aee25c",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "NlAUt5yvqEL2"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "6bc67c6f-ca80-4cb8-b215-59a14a2c9dd7",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "ITRPPYySqEL2"
      },
      "outputs": [],
      "source": [
        "# Binary classification on the original dataset with MobileNet\n",
        "runExperiment(GetBestBinaryDenseNet121Model, densenet_preprocess_input, (224,224,3), 32, ORIGINAL_BINARY_DATASET_DIR,\n",
        "    'DenseNet121 + dense layers', 'binary', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "9ffae039-e6aa-4980-adb6-241e33e2c317",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "eaFUSA6JqEL2"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "5d5736bb-81de-488c-8260-6a1e515085d6",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "uwnrsLfuqEL3"
      },
      "outputs": [],
      "source": [
        "# Binary classification on the original dataset with Xception\n",
        "runExperiment(GetBestBinaryXceptionModel, xception_preprocess_input, (299,299,3), 32, ORIGINAL_BINARY_DATASET_DIR,\n",
        "    'Xception + dense layers', 'binary', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "a568b311-c8ce-4bf3-b388-027e8a6b2ce4",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "9AsV59veqEL3"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "3c24fa1a-7348-4f7d-bcf5-5d52ac82a77c",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "PW3leSvVqEL3"
      },
      "source": [
        "### 3.2 Experiments with the augmented binary dataset\n",
        "\n",
        "The following cells run the **tests on the augmented binary dataset**, model by model, for each of the ten compared neural networks. Before running the experiments a folder to store the AUC-ROC plots of the experiments is created. After each experiments, the imagenet weights of the tested neural network can be deleted, in case limited disk space is available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "aadb8a72-730d-456e-97b6-69d5ca1a5835",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "UUdsa_6PqEL3"
      },
      "outputs": [],
      "source": [
        "# Creates a folder to store the results of experiments with the augmented binary dataset\n",
        "!mkdir augmented-binary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "d1b8822e-cb1f-4c56-8c07-ce57af1b8d40",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "P9fF4HR4qEL3"
      },
      "outputs": [],
      "source": [
        "# Binary classification on the augmented dataset with VGG16\n",
        "runExperiment(GetBestBinaryVGG16Model, vgg16_preprocess_input, (224,224,3), 32, AUGMENTED_BINARY_DATASET_DIR,\n",
        "    'VGG16 + dense layers', 'augmented-binary', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "758e6017-cb72-4da2-b5f9-ce8151a87c6c",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "Km9H84j5qEL4"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "0b5b5dcf-1b35-4ff7-b012-89926c5d6be6",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "tcsi_47AqEL4"
      },
      "outputs": [],
      "source": [
        "# Binary classification on the augmented dataset with VGG19\n",
        "runExperiment(GetBestBinaryVGG19Model, vgg19_preprocess_input, (224,224,3), 32, AUGMENTED_BINARY_DATASET_DIR,\n",
        "    'VGG19 + dense layers', 'augmented-binary', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "94d96943-bc52-42a9-ad24-9d7e1905a7b8",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "odzkItZpqEL5"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "7a95fa55-d367-482c-a6b2-c5c0d784a974",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "uK33e2DkqEL5"
      },
      "outputs": [],
      "source": [
        "# Binary classification on the augmented dataset with ResNet50V2\n",
        "runExperiment(GetBestBinaryResNet50V2Model, resnet_v2_preprocess_input, (224,224,3), 32, AUGMENTED_BINARY_DATASET_DIR,\n",
        "    'ResNet50V2 + dense layers', 'augmented-binary', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "392d56d7-42ab-41d1-b2a3-e31b89b1800e",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "wJs3thdfqEL5"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "161230f6-233d-4a73-9448-e109b8b83cf0",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "nvkos15FqEL5"
      },
      "outputs": [],
      "source": [
        "# Binary classification on the augmented dataset with ResNet101V2\n",
        "runExperiment(GetBestBinaryResNet101V2Model, resnet_v2_preprocess_input, (224,224,3), 32, AUGMENTED_BINARY_DATASET_DIR,\n",
        "    'ResNet101V2 + dense layers', 'augmented-binary', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "b2a9c18b-7f04-46e5-8af8-859e65309b5e",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "Vmz8q_uDqEL6"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "91529b43-dc9a-4098-a776-4b9a91775de5",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "iW1FZCSVqEL6"
      },
      "outputs": [],
      "source": [
        "# Binary classification on the augmented dataset with ResNet152V2\n",
        "runExperiment(GetBestBinaryResNet152V2Model, resnet_v2_preprocess_input, (224,224,3), 32, AUGMENTED_BINARY_DATASET_DIR,\n",
        "    'ResNet152V2 + dense layers', 'augmented-binary', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "47f637d4-2fe1-4220-bbd8-961a33d91d30",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "qLk0vgjVqEL6"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "977e9670-508f-4291-af98-7301ba487e1d",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "BxqmskmsqEL6"
      },
      "outputs": [],
      "source": [
        "# Binary classification on the augmented dataset with InceptionV3\n",
        "runExperiment(GetBestBinaryInceptionV3Model, inception_v3_preprocess_input, (299,299,3), 32, AUGMENTED_BINARY_DATASET_DIR,\n",
        "    'InceptionV3 + dense layers', 'augmented-binary', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "7726d4fa-fb32-468d-84f9-508ba73cde25",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "caKgYG-NqEL8"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "9baf1b96-89e5-4212-a302-e19999888366",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "9sgVn8piqEL8"
      },
      "outputs": [],
      "source": [
        "# Binary classification on the augmented dataset with MobileNetV2\n",
        "runExperiment(GetBestBinaryMobileNetV2Model, mobilenet_v2_preprocess_input, (224,224,3), 32, AUGMENTED_BINARY_DATASET_DIR,\n",
        "    'MobileNetV2 + dense layers', 'augmented-binary', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "a27d3360-dff9-46e6-bbaa-9cf5652c24a9",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "BeaqAa8kqEL8"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "02ebf1df-0b20-4e5f-b9ff-c8aa5a453496",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "bxi8By_zqEL8"
      },
      "outputs": [],
      "source": [
        "# Binary classification on the augmented dataset with NASNetMobile\n",
        "runExperiment(GetBestBinaryNasNetMobileModel, nasnet_preprocess_input, (224,224,3), 32, AUGMENTED_BINARY_DATASET_DIR,\n",
        "    'NASNetMobile + dense layers', 'augmented-binary', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "75562375-7d49-45f8-bd34-2424b7eeae52",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "a_xiqaZkqEL9"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "0a6b8d7f-4917-466e-b1f7-b720f3f664f8",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "iKvXwwq2qEL9"
      },
      "outputs": [],
      "source": [
        "# Binary classification on the augmented dataset with DenseNet121\n",
        "runExperiment(GetBestBinaryDenseNet121Model, densenet_preprocess_input, (224,224,3), 32, AUGMENTED_BINARY_DATASET_DIR,\n",
        "    'DenseNet121 + dense layers', 'augmented-binary', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "d3f75be4-1743-4d79-9ea4-c865b777497f",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "-z_9qyPDqEL9"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "fe20758d-43ed-4453-816f-0e4ff38a1a99",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "THdSd5bRqEL9"
      },
      "outputs": [],
      "source": [
        "# Binary classification on the augmented dataset with Xception\n",
        "runExperiment(GetBestBinaryXceptionModel, xception_preprocess_input, (299,299,3), 32, AUGMENTED_BINARY_DATASET_DIR,\n",
        "    'Xception + dense layers', 'augmented-binary', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "1f4d0bd3-5c7b-4df8-bfb6-945add29b124",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e",
          "source_hidden": false
        },
        "id": "nsgGMf6HqEL-"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "2818bf46-99e0-4939-b0d8-5c898a729104",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "AGEdDj1nLoOF"
      },
      "source": [
        "## 4 Multi-class classification experiments\n",
        "\n",
        "The following cells:\n",
        "\n",
        "- define an utility class to load training and test samples from disk during the experiments, in order to avoid keeping all the dataset in RAM;\n",
        "- define **ten utility functions to build the ten end-to-end deep neural networks** developed for the experiments to test the multi-class classification of carbon look component images into negative (no defects), with recoverable defects, and with non-recoverable defects;\n",
        "- define the **utility function to run an experiment with the multi-class classification**. An experiment consists of tests repeated 10 times with the **stratified shuffle split cross-validation scheme**. In each split 80% of data are used for training, and 20% of data are used for testing. 12,5% of the training data (i.e. 10% of the entire dataset) is used for validation. In other words, in each test **70% of data are actually for training, 10% for validation, and 20% for testing.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "1e97b9f9-d920-4dc0-984c-4aec50ec1937",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "vdopQ8GALrzK"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "from scipy import interp\n",
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "class DataGen(Sequence) :\n",
        "    \"\"\" A sequence of data for training/test/validation, loaded from memory\n",
        "    batch by batch. Extends the tensorflow.keras.utils.Sequence: https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    base_path : str\n",
        "                path to the folder including the samples.\n",
        "    filenames : list<str>\n",
        "                list of sample filenames.\n",
        "    labels : list<str>\n",
        "             list of sample labels.\n",
        "    batch_size : int\n",
        "                 batch size to load samples\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, Preprocess_input, base_path, filenames, labels, input_shape, batch_size) :\n",
        "        self.Preprocess_input = Preprocess_input\n",
        "        self.base_path = base_path\n",
        "        self.filenames = filenames\n",
        "        self.labels = labels\n",
        "        self.input_shape = input_shape\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "\n",
        "    def __len__(self) :\n",
        "        return (np.ceil(len(self.filenames) / float(self.batch_size))).astype(np.int)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx) :\n",
        "        batch_x = self.filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n",
        "        batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n",
        "        index = 0\n",
        "        imgs_array = np.ones((len(batch_x), self.input_shape[0], self.input_shape[1], self.input_shape[2]))\n",
        "\n",
        "        for file_name in batch_x:\n",
        "            imgs = load_img(file_name, target_size=(self.input_shape[0], self.input_shape[1]))\n",
        "            imgs = img_to_array(imgs)\n",
        "            imgs = imgs.reshape((1, imgs.shape[0], imgs.shape[1], imgs.shape[2]))\n",
        "            imgs = self.Preprocess_input(imgs)\n",
        "            imgs_array[index,:,:,:] = imgs\n",
        "            index += 1\n",
        "\n",
        "        return imgs_array, np.array(batch_y)\n",
        "\n",
        "\n",
        "def GetBestThreeClassesVGG16Model(print_summary=True) :\n",
        "    return GetEndToEndModel(GetPretrainedModel, VGG16, optimizers.SGD(learning_rate=0.001, momentum=0.9),\n",
        "    'categorical_crossentropy', (224,224,3), print_summary, 8, True, True, [512], 3)\n",
        "\n",
        "def GetBestThreeClassesVGG19Model(print_summary=True) :\n",
        "    return GetEndToEndModel(GetPretrainedModel, VGG19, optimizers.SGD(learning_rate=0.001, momentum=0.9),\n",
        "    'categorical_crossentropy', (224,224,3), print_summary, 8, True, True, [512], 3)\n",
        "\n",
        "def GetBestThreeClassesResNet50V2Model(print_summary=True) :\n",
        "    return GetEndToEndModel(GetPretrainedModel, ResNet50V2, optimizers.Adam(learning_rate=0.001),\n",
        "    'categorical_crossentropy', (224,224,3), print_summary, 8, True, False, [512], 3)\n",
        "\n",
        "def GetBestThreeClassesResNet101V2Model(print_summary=True) :\n",
        "    return GetEndToEndModel(GetPretrainedModel, ResNet101V2, optimizers.Adam(learning_rate=0.001),\n",
        "    'categorical_crossentropy', (224,224,3), print_summary, 8, True, False, [512], 3)\n",
        "\n",
        "def GetBestThreeClassesResNet152V2Model(print_summary=True) :\n",
        "    return GetEndToEndModel(GetPretrainedModel, ResNet152V2, optimizers.Adam(learning_rate=0.001),\n",
        "    'categorical_crossentropy', (224,224,3), print_summary, 8, True, False, [512], 3)\n",
        "\n",
        "def GetBestThreeClassesInceptionV3Model(print_summary=True) :\n",
        "    return GetEndToEndModel(GetPretrainedModel, InceptionV3, optimizers.Adam(learning_rate=0.0001),\n",
        "    'categorical_crossentropy', (299,299,3), print_summary, 8, True, False, [512], 3)\n",
        "\n",
        "def GetBestThreeClassesMobileNetV2Model(print_summary=True) :\n",
        "    return GetEndToEndModel(GetPretrainedModel, MobileNetV2, optimizers.SGD(learning_rate=0.0001, momentum=0.9),\n",
        "    'categorical_crossentropy', (224,224,3), print_summary, 8, True, False, [512], 3)\n",
        "\n",
        "def GetBestThreeClassesNasNetMobileModel(print_summary=True) :\n",
        "    return GetEndToEndModel(GetPretrainedModel, NASNetMobile, optimizers.Adam(learning_rate=0.0001),\n",
        "    'categorical_crossentropy', (224,224,3), print_summary, 8, True, False, [512], 3)\n",
        "\n",
        "def GetBestThreeClassesDenseNet121Model(print_summary=True) :\n",
        "    return GetEndToEndModel(GetPretrainedModel, DenseNet121, optimizers.Adam(learning_rate=0.0001),\n",
        "    'categorical_crossentropy', (224,224,3), print_summary, 8, True, False, [512], 3)\n",
        "\n",
        "def GetBestThreeClassesXceptionModel(print_summary=True) :\n",
        "    return GetEndToEndModel(GetPretrainedModel, Xception, optimizers.Adam(learning_rate=0.0001),\n",
        "    'categorical_crossentropy', (299,299,3), print_summary, 4, True, False, [512], 3)\n",
        "\n",
        "def runThreeClassesExperiment(GetConvModel, Preprocess_input, input_shape, batchSize,\n",
        "                              path, Model_name, folderName, rState, split_number=5):\n",
        "\n",
        "    \"\"\"\" Runs a classifier test on the dataset composed of three classes (no\n",
        "    defects, non-recoverable defects, recoverable defects), using the stratified\n",
        "    shuffled splits, with 70% of data for training, 10% for validation, 20% for test.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    GetConvModel : Callable[Sequential]\n",
        "                   Function returning the sequential model to be tested.\n",
        "    Preprocess_input : Callable[[][]]\n",
        "    input_shape : tuple\n",
        "                  Shape of a model's input.\n",
        "    batchSize : int\n",
        "                Batch size to be used for training and testing\n",
        "    path : str\n",
        "           Path to the folder with images to be processed\n",
        "    Model_name : str\n",
        "                 Model name to be used in the title of AUC-ROC plot\n",
        "    folderName : str\n",
        "                 Name for the folder to store the AUC-ROC plot.\n",
        "    rState : int, RandomState instance or None\n",
        "             Controls the randomness of the training and testing indices produced.\n",
        "             Pass an int for reproducible output across multiple function calls.\n",
        "    split_number : int\n",
        "                   Number of split to run the Stratified Shuffle Split (default 5)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Prepare samples tensor and label array\n",
        "    negative = os.listdir(path + '/negative/')\n",
        "    count_negative = len(negative)\n",
        "    print(\"Negative images: \", count_negative)\n",
        "    non_recoverable_defects = os.listdir(path + '/non_recoverable_defects/')\n",
        "    count_non_recoverable_defects = len(non_recoverable_defects)\n",
        "    print(\"Non recoverable defects images: \", count_non_recoverable_defects)\n",
        "    recoverable_defects = os.listdir(path + '/recoverable_defects/')\n",
        "    count_recoverable_defects = len(recoverable_defects)\n",
        "    print(\"Recoverable defects images: \", count_recoverable_defects)\n",
        "    total_samples = count_negative + count_non_recoverable_defects + count_recoverable_defects\n",
        "    print(\"Total images: \", total_samples)\n",
        "    filenames = []\n",
        "    label_array = []\n",
        "\n",
        "    index = 0\n",
        "\n",
        "    for defect_type in os.listdir(path):\n",
        "        read_path = path + '/' + defect_type + '/'\n",
        "        for filename in os.listdir(read_path):\n",
        "            filenames.append(os.path.join(read_path, filename))\n",
        "            if defect_type == 'negative':\n",
        "                label_array.append(0)\n",
        "            elif defect_type == 'non_recoverable_defects':\n",
        "                label_array.append(1)\n",
        "            elif defect_type == 'recoverable_defects':\n",
        "                label_array.append(2)\n",
        "            index += 1\n",
        "\n",
        "    X = np.array(filenames)\n",
        "    y = label_array\n",
        "\n",
        "    y = label_binarize(y, classes=[0, 1, 2])\n",
        "    n_classes = y.shape[1]\n",
        "    nsplits = split_number\n",
        "    #cv = StratifiedKFold(n_splits=nsplits, shuffle=True)\n",
        "    cv = StratifiedShuffleSplit(n_splits=nsplits, train_size=0.8, random_state = rState)\n",
        "\n",
        "    tprs = []\n",
        "    aucs = []\n",
        "    scores = []\n",
        "    prec_negative = np.zeros(shape=(nsplits))\n",
        "    prec_nrd = np.zeros(shape=(nsplits))\n",
        "    prec_rd = np.zeros(shape=(nsplits))\n",
        "    #prec = np.zeros(shape=(nsplits))\n",
        "    recall_negative = np.zeros(shape=(nsplits))\n",
        "    recall_nrd = np.zeros(shape=(nsplits))\n",
        "    recall_rd = np.zeros(shape=(nsplits))\n",
        "    #recall = np.zeros(shape=(nsplits))\n",
        "    f1Scores_negative = np.zeros(shape=(nsplits))\n",
        "    f1Scores_nrd = np.zeros(shape=(nsplits))\n",
        "    f1Scores_rd = np.zeros(shape=(nsplits))\n",
        "    #f1Scores = np.zeros(shape=(nsplits))\n",
        "    mean_fpr = np.linspace(0, 1, 100)\n",
        "    plt.figure(num=1, figsize=(10,10))\n",
        "    i = 1\n",
        "\n",
        "    for train, test in cv.split(X, y):\n",
        "        X_train, X_val, y_train, y_val = train_test_split(X[train][:], y[train], test_size = 0.125, random_state = rState)\n",
        "        X_test, y_test = X[test], y[test]\n",
        "        model = GetConvModel(i==1)\n",
        "        es = EarlyStopping(monitor='val_loss', mode='min', patience=5, verbose=1, restore_best_weights=True)\n",
        "        #history = model.fit(x=X_train, y=y_train, validation_data=(X_val, y_val), epochs=100, batch_size=batchSize, verbose=1, callbacks=[es], shuffle=True)\n",
        "        training_batch_generator = DataGen(Preprocess_input, '', X_train, y_train, input_shape, batchSize)\n",
        "        validation_batch_generator = DataGen(Preprocess_input, '', X_val, y_val, input_shape, batchSize)\n",
        "        test_batch_generator = DataGen(Preprocess_input, '', X[test][:], y[test], input_shape, batchSize)\n",
        "        history = model.fit(x=training_batch_generator, validation_data=validation_batch_generator, epochs=100, batch_size=batchSize, verbose=1, callbacks=[es], shuffle=True)\n",
        "\n",
        "        del X_train\n",
        "        del X_val\n",
        "\n",
        "        print(\"\\nComputing scores...\")\n",
        "        evaluation = model.evaluate(x=test_batch_generator)\n",
        "        scores.append(evaluation)\n",
        "        print(\"Computing probs...\")\n",
        "        probas = model.predict(x=test_batch_generator, batch_size=batchSize, verbose=1)\n",
        "        y_true = y_test.argmax(axis=1)\n",
        "        pred = probas.argmax(axis=1)\n",
        "\n",
        "        #del X_test\n",
        "\n",
        "        # Compute ROC curve and area under the curve\n",
        "        fpr = dict()\n",
        "        tpr = dict()\n",
        "        roc_auc = dict()\n",
        "\n",
        "        for k in range(n_classes):\n",
        "            fpr[k], tpr[k], _ = roc_curve(y_test[:, k], probas[:, k])\n",
        "            roc_auc[k] = auc(fpr[k], tpr[k])\n",
        "\n",
        "        # Compute micro-average ROC curve and ROC area\n",
        "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), probas.ravel())\n",
        "        tprs.append(np.interp(mean_fpr, fpr[\"micro\"], tpr[\"micro\"]))\n",
        "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "        aucs.append(roc_auc[\"micro\"])\n",
        "        plt.plot(fpr[\"micro\"], tpr[\"micro\"], lw=2, alpha=0.3, label='ROC split %d (AUC = %0.4f)' % (i, roc_auc[\"micro\"]))\n",
        "\n",
        "        y_pred = np.round(pred)\n",
        "        report = classification_report(y_true, y_pred, target_names=['negative', 'non_recoverable_defects', 'recoverable_defects'], output_dict=True)\n",
        "        prec_negative[i - 1] = report['negative']['precision']\n",
        "        prec_nrd[i - 1] = report['non_recoverable_defects']['precision']\n",
        "        prec_rd[i - 1] = report['recoverable_defects']['precision']\n",
        "\n",
        "        recall_negative[i - 1] = report['negative']['recall']\n",
        "        recall_nrd[i - 1] = report['non_recoverable_defects']['recall']\n",
        "        recall_rd[i - 1] = report['recoverable_defects']['recall']\n",
        "\n",
        "        f1Scores_negative[i - 1] = report['negative']['f1-score']\n",
        "        f1Scores_nrd[i - 1] = report['non_recoverable_defects']['f1-score']\n",
        "        f1Scores_rd[i - 1] = report['recoverable_defects']['f1-score']\n",
        "\n",
        "        print('\\nconfusion matrix split ' + str(i))\n",
        "        print(confusion_matrix(y_true, y_pred))\n",
        "        print(classification_report(y_true, y_pred, target_names=['negative', 'non_recoverable_defects', 'recoverable_defects']))\n",
        "        print('Loss: ' + str(evaluation[0]))\n",
        "        print('Accuracy: ' + str(evaluation[1]))\n",
        "        print('\\n')\n",
        "\n",
        "        i += 1\n",
        "\n",
        "        del report\n",
        "        del model\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Chance', alpha=.8)\n",
        "\n",
        "    mean_tpr = np.mean(tprs, axis=0)\n",
        "    mean_auc = auc(mean_fpr, mean_tpr)\n",
        "    std_auc = np.std(aucs)\n",
        "    plt.plot(mean_fpr, mean_tpr, color='b', label=r'Mean ROC (AUC = %0.4f $\\pm$ %0.4f)' % (mean_auc, std_auc), lw=2, alpha=.8)\n",
        "\n",
        "    std_tpr = np.std(tprs, axis=0)\n",
        "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
        "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
        "    plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2, label=r'$\\pm$ 1 std. dev.')\n",
        "\n",
        "    plt.xlim([-0.01, 1.01])\n",
        "    plt.ylim([-0.01, 1.01])\n",
        "    plt.xlabel('False Positive Rate',fontsize=18)\n",
        "    plt.ylabel('True Positive Rate',fontsize=18)\n",
        "    plt.title('Cross-Validation ROC of ' + Model_name + ' model', fontsize=18)\n",
        "    plt.legend(loc=\"lower right\", prop={'size': 15})\n",
        "\n",
        "    np_scores = np.array(scores)\n",
        "    losses = np_scores[:, 0:1]\n",
        "    accuracies = np_scores[:, 1:2]\n",
        "    print('Losses')\n",
        "    print(losses)\n",
        "    print('Accuracies')\n",
        "    print(accuracies)\n",
        "\n",
        "    print('Precision class negative:\\n', prec_negative)\n",
        "    print('Precision class non_recoverable_defects:\\n', prec_nrd)\n",
        "    print('Precision class recoverable_defects:\\n', prec_rd)\n",
        "\n",
        "    print('Recall class negative:\\n', recall_negative)\n",
        "    print('Recall class non_recoverable_defects:\\n', recall_nrd)\n",
        "    print('Recall class recoverable_defects:\\n', recall_rd)\n",
        "\n",
        "    print('F1-scores class negative:\\n', f1Scores_negative)\n",
        "    print('F1-scores class non_recoverable_defects:\\n', f1Scores_nrd)\n",
        "    print('F1-scores class recoverable_defects:\\n', f1Scores_rd)\n",
        "\n",
        "    print(\"Avg loss: {0} +/- {1}\".format(np.mean(losses), np.std(losses)))\n",
        "    print(\"Avg accuracy: {0} +/- {1}\".format(np.mean(accuracies), np.std(accuracies)))\n",
        "    print(\"\\nAvg Precision class negative: {0} +/- {1}\".format(np.mean(prec_negative), np.std(prec_negative)))\n",
        "    print(\"Avg Precision class non_recoverable_defects: {0} +/- {1}\".format(np.mean(prec_nrd), np.std(prec_nrd)))\n",
        "    print(\"Avg Precision class recoverable_defects: {0} +/- {1}\".format(np.mean(prec_rd), np.std(prec_rd)))\n",
        "    print(\"\\nAvg Recall class negative: {0} +/- {1}\".format(np.mean(recall_negative), np.std(recall_negative)))\n",
        "    print(\"Avg Recall class non_recoverable_defects: {0} +/- {1}\".format(np.mean(recall_nrd), np.std(recall_nrd)))\n",
        "    print(\"Avg Recall class recoverable_defects: {0} +/- {1}\".format(np.mean(recall_rd), np.std(recall_rd)))\n",
        "    print(\"\\nAvg f1-score class negative: {0} +/- {1}\".format(np.mean(f1Scores_negative), np.std(f1Scores_negative)))\n",
        "    print(\"Avg f1-score class non_recoverable_defects: {0} +/- {1}\".format(np.mean(f1Scores_nrd), np.std(f1Scores_nrd)))\n",
        "    print(\"Avg f1-score class recoverable_defects: {0} +/- {1}\".format(np.mean(f1Scores_rd), np.std(f1Scores_rd)))\n",
        "\n",
        "    plt.savefig(folderName + '/' + Model_name.replace('+', '') + '.pdf')\n",
        "    plt.show()\n",
        "\n",
        "    del label_array\n",
        "    del X\n",
        "    del y\n",
        "    del prec_negative\n",
        "    del prec_nrd\n",
        "    del prec_rd\n",
        "    del recall_negative\n",
        "    del recall_nrd\n",
        "    del recall_rd\n",
        "    del f1Scores_negative\n",
        "    del f1Scores_nrd\n",
        "    del f1Scores_rd\n",
        "    del accuracies\n",
        "    del losses\n",
        "    del np_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "d4a89c7c-d52b-4c0a-83d6-9917ccbf6877",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "FTTa4Vuuthj6"
      },
      "source": [
        "### 4.1 Experiments with the original multi-class dataset\n",
        "\n",
        "The following cells run the **tests on the original multi-class dataset**, model by model, for each of the ten compared neural networks. Before running the experiments a folder to store the AUC-ROC plots of the experiments is created. After each experiments, the imagenet weights of the tested neural network can be deleted, in case limited disk space is available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "91c09a47-57ef-411b-a63d-6e958b3f12d9",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "61ukcify3Qkw"
      },
      "outputs": [],
      "source": [
        "# Creates a folder to store the results of experiments with the multi-class dataset\n",
        "!mkdir 'multi'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "ced5c11b-ecdb-41a3-8db0-b1f245949986",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "9hBEzxoL3Lr-"
      },
      "outputs": [],
      "source": [
        "# Multi-class classification on the original dataset with VGG16\n",
        "runThreeClassesExperiment(GetBestThreeClassesVGG16Model, vgg16_preprocess_input, (224,224,3), 32, ORIGINAL_MULTI_DATASET_DIR,\n",
        "    'VGG16 + dense layers', 'multi', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "e80e9b62-0955-4035-8457-04eb6b7f517e",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "Jj2Bm2Tb3a2Y"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "b2426cd4-98b6-4194-97d9-7b587989fa41",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "BzYM77xI3cPP"
      },
      "outputs": [],
      "source": [
        "# Multi-class classification on the original dataset with VGG19\n",
        "runThreeClassesExperiment(GetBestThreeClassesVGG19Model, vgg19_preprocess_input, (224,224,3), 32, ORIGINAL_MULTI_DATASET_DIR,\n",
        "                          'VGG19 + dense layers', 'multi', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "f2bfdc14-f78f-4673-94d9-8ef1e1ca77e2",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "r2yJjBL63eag"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "a5867c94-6f56-4951-a9be-26d5fef536be",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "A-Rtfcsj3fGr"
      },
      "outputs": [],
      "source": [
        "# Multi-class classification on the original dataset with ResNet50V2\n",
        "runThreeClassesExperiment(GetBestThreeClassesResNet50V2Model, resnet_v2_preprocess_input, (224,224,3), 32, ORIGINAL_MULTI_DATASET_DIR,\n",
        "    'ResNet50V2 + dense layers', 'multi', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "c1bb5218-6b5e-4fd0-8fce-f0327ada4819",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "1SykMVW63gu7"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "6068021d-231b-4162-9453-5b3122f0876c",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "zsxrmcBV35gz"
      },
      "outputs": [],
      "source": [
        "# Multi-class classification on the original dataset with ResNet101V2\n",
        "runThreeClassesExperiment(GetBestThreeClassesResNet101V2Model, resnet_v2_preprocess_input, (224,224,3), 32, ORIGINAL_MULTI_DATASET_DIR,\n",
        "    'ResNet101V2 + dense layers', 'multi', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "f037aa70-3c3a-44e6-8cab-ddd85efb4cdf",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "GNX3urMW39iq"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "b9d52b5a-5ec7-4522-b592-75465f2b7d7c",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "ZQr6mvsQ3-YB"
      },
      "outputs": [],
      "source": [
        "# Multi-class classification on the original dataset with ResNet152V2\n",
        "runThreeClassesExperiment(GetBestThreeClassesResNet152V2Model, resnet_v2_preprocess_input, (224,224,3), 32, ORIGINAL_MULTI_DATASET_DIR,\n",
        "    'ResNet152V2 + dense layers', 'multi', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "a46f690b-9bce-4c88-800b-cb4175a54fe6",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "p3mdil2z4CcO"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "357b9171-6e5c-430b-9da3-739f6a72167e",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "ARRrsYVY4FnC"
      },
      "outputs": [],
      "source": [
        "# Multi-class classification on the original dataset with InceptionV3\n",
        "runThreeClassesExperiment(GetBestThreeClassesInceptionV3Model, inception_v3_preprocess_input, (299,299,3), 32, ORIGINAL_MULTI_DATASET_DIR,\n",
        "    'InceptionV3 + dense layers', 'multi', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "547ffcf1-d8aa-4e89-85a9-48b04effa5f1",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "_G-uPOA04Eds"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "e1ac7b37-3f38-464a-aad1-4a7e872ea13b",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "IXypZXHx4Quw"
      },
      "outputs": [],
      "source": [
        "# Multi-class classification on the original dataset with MobileNetV2\n",
        "runThreeClassesExperiment(GetBestThreeClassesMobileNetV2Model, mobilenet_v2_preprocess_input, (224,224,3), 32, ORIGINAL_MULTI_DATASET_DIR,\n",
        "    'MobileNetV2 + dense layers', 'multi', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "eafc0f2d-14b4-4e33-b12e-65bc7fc107ac",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "KUZpsCGx4ZHm"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "b7640565-1502-4df8-98c9-49fb6b0cc748",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "4x11WYvJ4b6e"
      },
      "outputs": [],
      "source": [
        "# Multi-class classification on the original dataset with NASNetMobile\n",
        "runThreeClassesExperiment(GetBestThreeClassesNasNetMobileModel, nasnet_preprocess_input, (224,224,3), 32, ORIGINAL_MULTI_DATASET_DIR,\n",
        "    'NASNetMobile + dense layers', 'multi', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "c48ed909-7bda-4276-ab80-0f1fb0b5e7e3",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "xp7DFGtG4nm_"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "effed05e-8782-43be-b444-9ca87b6e0144",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "mxxBzoox4pHN"
      },
      "outputs": [],
      "source": [
        "# Multi-class classification on the original dataset with DenseNet121\n",
        "runThreeClassesExperiment(GetBestThreeClassesDenseNet121Model, densenet_preprocess_input, (224,224,3), 32, ORIGINAL_MULTI_DATASET_DIR,\n",
        "    'DenseNet121 + dense layers', 'multi', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "b3ed4cef-473d-4dee-aed1-6ec1f036a4f1",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "HrowcXLZ5DGg"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "ad24014f-6fde-43ad-8834-45d8d36aa94f",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "xHbtQk6T4xX7"
      },
      "outputs": [],
      "source": [
        "# Multi-class classification on the original dataset with Xception\n",
        "runThreeClassesExperiment(GetBestThreeClassesXceptionModel, xception_preprocess_input, (299,299,3), 32, ORIGINAL_MULTI_DATASET_DIR,\n",
        "    'Xception + dense layers', 'multi', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "e7e6ac48-e0b9-4267-b371-820092c75047",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "N4knX3PV5BwW"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "6dfca084-18ff-4153-9173-197dc0487c02",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "IRJ6sekstmQb"
      },
      "source": [
        "### 4.2 Experiments with the original multi-class dataset\n",
        "\n",
        "The following cells run the **tests on the augmented multi-class dataset**, model by model, for each of the ten compared neural networks. Before running the experiments a folder to store the AUC-ROC plots of the experiments is created. After each experiments, the imagenet weights of the tested neural network can be deleted, in case limited disk space is available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "65b09598-0910-410f-a73a-0e8303176f2b",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "fFBvcXS_5krd"
      },
      "outputs": [],
      "source": [
        "# Creates a folder to store the results of experiments with the augmented multi-class dataset\n",
        "!mkdir 'augmented-multi'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "4964c8ad-cc40-4fdb-8253-362376ec35c6",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "D4G-vVD_5krd"
      },
      "outputs": [],
      "source": [
        "# Multi-class classification on the augmented dataset with VGG16\n",
        "runThreeClassesExperiment(GetBestThreeClassesVGG16Model, vgg16_preprocess_input, (224,224,3), 32, AUGMENTED_MULTI_DATASET_DIR,\n",
        "    'VGG16 + dense layers', 'augmented-multi', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "de17f368-6c98-4c7e-8fd7-0d41b4c2195c",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "KvVC7Z1B5krd"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "cf661919-cec2-4716-8deb-b9a52f6fd658",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "eVfhbFrY5kre"
      },
      "outputs": [],
      "source": [
        "# Multi-class classification on the augmented dataset with VGG19\n",
        "runThreeClassesExperiment(GetBestThreeClassesVGG19Model, vgg19_preprocess_input, (224,224,3), 32, AUGMENTED_MULTI_DATASET_DIR,\n",
        "                          'VGG19 + dense layers', 'augmented-multi', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "99393046-6088-4ba0-8d15-7383a3f11603",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "bK6L8Wry5kre"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "0d792c30-0f75-401f-ba9a-474034707383",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "YDGNKzOB5kre"
      },
      "outputs": [],
      "source": [
        "# Multi-class classification on the augmented dataset with ResNet50V2\n",
        "runThreeClassesExperiment(GetBestThreeClassesResNet50V2Model, resnet_v2_preprocess_input, (224,224,3), 32, AUGMENTED_MULTI_DATASET_DIR,\n",
        "    'ResNet50V2 + dense layers', 'augmented-multi', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "b1db9667-07fe-4521-a5b8-bb09b66c13fc",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "DTVNLgwC5kre"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "186f8a4c-fa04-454e-a484-a8c9358c186e",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "uu1sbm9i5kre"
      },
      "outputs": [],
      "source": [
        "# Multi-class classification on the augmented dataset with ResNet101V2\n",
        "runThreeClassesExperiment(GetBestThreeClassesResNet101V2Model, resnet_v2_preprocess_input, (224,224,3), 32, AUGMENTED_MULTI_DATASET_DIR,\n",
        "    'ResNet101V2 + dense layers', 'augmented-multi', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "0976d859-7824-4a10-92ed-da33aa0c300f",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "1TgN6QYr5kre"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "c4805f94-35cb-4481-a0cf-aeab22632602",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "swk1DAUg5kre"
      },
      "outputs": [],
      "source": [
        "# Multi-class classification on the augmented dataset with ResNet152V2\n",
        "runThreeClassesExperiment(GetBestThreeClassesResNet152V2Model, resnet_v2_preprocess_input, (224,224,3), 32, AUGMENTED_MULTI_DATASET_DIR,\n",
        "    'ResNet152V2 + dense layers', 'augmented-multi', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "74351eab-768c-4211-bc3a-ad2bc758efd7",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "SxkNzlM35kre"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "8e54a5c0-ad93-4abd-8c87-fcee0b73f911",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "NDvle89Y5kre"
      },
      "outputs": [],
      "source": [
        "# Multi-class classification on the augmented dataset with InceptionV3\n",
        "runThreeClassesExperiment(GetBestThreeClassesInceptionV3Model, inception_v3_preprocess_input, (299,299,3), 32, AUGMENTED_MULTI_DATASET_DIR,\n",
        "    'InceptionV3 + dense layers', 'augmented-multi', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "f458845d-3a37-440d-ba1a-d066cfc6fc54",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "PcZsZk175kre"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gradient": {
          "editing": false,
          "id": "3751d0ee-669a-4062-a1b0-a472aa6c6fc1",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "afQdwLAm5krf"
      },
      "outputs": [],
      "source": [
        "# Multi-class classification on the augmented dataset with MobileNetV2\n",
        "runThreeClassesExperiment(GetBestThreeClassesMobileNetV2Model, mobilenet_v2_preprocess_input, (224,224,3), 32, AUGMENTED_MULTI_DATASET_DIR,\n",
        "    'MobileNetV2 + dense layers', 'augmented-multi', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "97e03541-f0a9-45c4-a9ee-bb75fc449243",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "z9iwt5F_5krf"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "cc6e9cf3-bfb8-433a-a9ae-92bad8508774",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "li5-m-lP5krf"
      },
      "outputs": [],
      "source": [
        "# Multi-class classification on the augmented dataset with NASNetMobile\n",
        "runThreeClassesExperiment(GetBestThreeClassesNasNetMobileModel, nasnet_preprocess_input, (224,224,3), 32, AUGMENTED_MULTI_DATASET_DIR,\n",
        "    'NASNetMobile + dense layers', 'augmented-multi', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "c918b592-be90-4980-bc29-4c48b036fa1d",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "21bYK1mf5krf"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "7b6d208a-e7bd-46c2-854e-014fa7135d8d",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "CT-qpq0G5krf"
      },
      "outputs": [],
      "source": [
        "# Multi-class classification on the augmented dataset with DenseNet121\n",
        "runThreeClassesExperiment(GetBestThreeClassesDenseNet121Model, densenet_preprocess_input, (224,224,3), 32, AUGMENTED_MULTI_DATASET_DIR,\n",
        "    'DenseNet121 + dense layers', 'augmented-multi', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "1ca489fc-2dec-4e82-b97c-3e8ef2982a44",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "PeYjYg4M5krf"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "a3f1140e-f722-4f65-a942-6213de4c7a71",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "B9tx8Odz5krf"
      },
      "outputs": [],
      "source": [
        "# Multi-class classification on the augmented dataset with Xception\n",
        "runThreeClassesExperiment(GetBestThreeClassesXceptionModel, xception_preprocess_input, (299,299,3), 32, AUGMENTED_MULTI_DATASET_DIR,\n",
        "    'Xception + dense layers', 'augmented-multi', 42, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "ec0246e4-6874-4249-a15b-c0ecd16cbc75",
          "kernelId": "48b63a99-1faa-4d32-a9ce-924c6bbe565e"
        },
        "id": "ZROTxzPT5krf"
      },
      "outputs": [],
      "source": [
        "# Run this to delete the weights of the previously tested neuraln networks, in\n",
        "# case you have limited disk space\n",
        "!rm -r ~/.keras/models/*\n",
        "!ls ~/.keras/models/"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}